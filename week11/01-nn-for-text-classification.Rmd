---
title: "Neural networks for text classification"
date: "25 March 2024"
output: html_document
---

--------------------------------------------------------------------------------

#### Preliminary notes

To install `keras` and run the notebooks from this week:

1. Run `install.packages("keras")`
2. Load the package with `library("keras")`
3. Then run the function `install_keras()` in the R-console

Afterwards the code in this notebook should run properly.

For more information on `tensorflow` (the basis of `keras`) see: https://tensorflow.rstudio.com/install/index.html

For issues resulting from already existing Python installations, the following can be helpful: https://tensorflow.rstudio.com/install/custom

--------------------------------------------------------------------------------

The following code example is taken from https://github.com/rstudio/keras/blob/01a2b5205562dfd58dcde5bea399b26c72b49b1b/vignettes/examples/reuters_mlp.R. It briefly illustrates how easily neural networks for tasks like text classification can be set up and trained through high-level libraries such as `keras`.

```{r}
library(keras)
```

Processing the data:

```{r}
# Considering only the max_words most frequent words
max_words <- 1000

# Loading data
reuters <- dataset_reuters(num_words = max_words, test_split = 0.2)
x_train <- reuters$train$x
y_train <- reuters$train$y
x_test <- reuters$test$x
y_test <- reuters$test$y

cat(length(x_train), 'train sequences\n')
cat(length(x_test), 'test sequences\n')

num_classes <- max(y_train) + 1 # +1 because y labels start at 0
cat(num_classes, 'labels\n')


# Transform text into relative frequency matrix (mode = "count" would create dfm)
tokenizer <- text_tokenizer(num_words = max_words)
x_train <- sequences_to_matrix(tokenizer, x_train, mode = "freq")
x_test <- sequences_to_matrix(tokenizer, x_test, mode = "freq")

cat('x_train shape:', dim(x_train), '\n')
cat('x_test shape:', dim(x_test), '\n')

# Create one-hot labels
y_train <- to_categorical(y_train, num_classes)
y_test <- to_categorical(y_test, num_classes)
cat('y_train shape:', dim(y_train), '\n')
cat('y_test shape:', dim(y_test), '\n')

```

Creating the model:

```{r}

cat('Building model...\n')

model <- keras_model_sequential()
model %>%
  layer_dense(units = 512, input_shape = c(max_words)) %>% 
  layer_activation(activation = 'relu') %>% 
  layer_dropout(rate = 0.5) %>% 
  layer_dense(units = num_classes) %>% 
  layer_activation(activation = 'softmax')

model %>% compile(
  loss = 'categorical_crossentropy',
  optimizer = optimizer_adam(learning_rate = 0.01),
  metrics = c('accuracy')
)
model
```

Training:

```{r}
batch_size <- 256
epochs <- 15

history <- model %>% fit(
  x_train, y_train,
  batch_size = batch_size,
  epochs = epochs,
  verbose = 1,
  validation_split = 0.1,
)
```

Test set accuracy:

```{r}
score <- model %>% evaluate(
  x_test, y_test,
  batch_size = batch_size,
  verbose = 1
)

cat('Test loss:', score[[1]], '\n')
cat('Test accuracy', score[[2]], '\n')
```

References:

- https://github.com/rstudio/keras/blob/01a2b5205562dfd58dcde5bea399b26c72b49b1b/vignettes/examples/reuters_mlp.R
